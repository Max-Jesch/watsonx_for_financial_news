{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/datasets/notlucasp/financial-news-headlines/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import csv\n",
    "import datetime\n",
    "from langchain.prompts import PromptTemplate\n",
    "from genai.credentials import Credentials\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "# Using Generative AI Library\n",
    "from genai.model import Model\n",
    "from genai.schemas import GenerateParams\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "# Suppress all warnings\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the csv file data/reuters_headlines.csv into a dataframe\n",
    "df = pd.read_csv('data/reuters_headlines.csv',nrows=1000)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv(\"GENAI_KEY\")\n",
    "api_url = os.getenv(\"GENAI_API\")\n",
    "\n",
    "creds = Credentials(api_key, api_endpoint=api_url) # credentials object to access the LLM service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a helper function to generate text\n",
    "def get_completion(sample, prompt_string, model):\n",
    "    prompt_template = PromptTemplate.from_template(prompt_string)\n",
    "    prompt=prompt_template.format(sample=sample)\n",
    "    result=model.generate([prompt])[0].generated_text\n",
    "    # print(sample)\n",
    "    # print(result)\n",
    "    # print(\" \")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model type\n",
    "#MODELTYPE = \"meta-llama/llama-2-70b-chat\"\n",
    "MODELTYPE = \"ibm/granite-13b-chat-v1\"\n",
    "# MODELTYPE = \"ibm/granite-13b-sft\"\n",
    "\n",
    "\n",
    "# Instantiate parameters for text generation\n",
    "params = GenerateParams(\n",
    "    decoding_method=\"sample\", # use 'greedy' alternatively\n",
    "    max_new_tokens=1000,\n",
    "    min_new_tokens=1,\n",
    "    temperature=0.5,\n",
    "    repetition_penalty=1.2,\n",
    "    top_k=50,\n",
    "    top_p=1,\n",
    ")\n",
    "\n",
    "# Instantiate a model proxy object to send your requests\n",
    "granite_13_chat_model = Model(MODELTYPE, params=params, credentials=creds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_string_sentiment_analysis=\"\"\"\n",
    "Analyze the sentiment of the following financial article.Determine whether the sentiment is positive, negative, or neutral. Answer with only one word!: \n",
    "\n",
    "financial article:\n",
    "\"{sample}\" \n",
    "\n",
    "sentiment:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "def process_row_sentiment(index, row):\n",
    "    sentiment = get_completion(row['Description'], prompt_string_sentiment_analysis, granite_13_chat_model)\n",
    "    return index, sentiment\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    # Creating a list of futures\n",
    "    futures = [executor.submit(process_row_sentiment, i, row) for i, row in df.iterrows()]\n",
    "\n",
    "    # Retrieving results and updating the DataFrame\n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        index, sentiment = future.result()\n",
    "        df.at[index, 'sentiment'] = sentiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over the rows of the dataframe and get_completion for each Description and store the result in a new column called 'sentiment'\n",
    "# df['sentiment'] = df['Description'].apply(get_completion,prompt_string,granite_13_chat_model)\n",
    "df['sentiment'] = df['Description'].apply(lambda x: get_completion(x, prompt_string_sentiment_analysis, granite_13_chat_model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extract named entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Instantiate parameters for text generation\n",
    "params = GenerateParams(\n",
    "    decoding_method=\"greedy\", # use 'greedy' alternatively\n",
    "    # max_new_tokens=1000,\n",
    "    # min_new_tokens=1,\n",
    "    # temperature=0.5,\n",
    "    # repetition_penalty=1.2,\n",
    "    # top_k=50,\n",
    "    # top_p=1,\n",
    ")\n",
    "\n",
    "# Instantiate a model proxy object to send your requests\n",
    "\n",
    "# llama 2 --> 100 rows = 180 seconds --> 1 row = 1.8 seconds --> 30000 rows = 54000 seconds = 15 hours\n",
    "llame_2_70b_model = Model(\"meta-llama/llama-2-70b-chat\", params=params, credentials=creds)\n",
    "# granite-13b-instruct-v1 --> 100 rows = 90 seconds --> 1 row = 0.9 seconds --> 30000 rows = 27000 seconds = 7.5 hours\n",
    "granite_13_instruct_model = Model(\"ibm/granite-13b-instruct-v1\", params=params, credentials=creds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_string_named_entities=\"\"\"\n",
    "Act as a webmaster who must extract structured information from emails. Read the below email and extract and categorize each entity.\n",
    "\n",
    "\n",
    "Input:\n",
    "\"Golden Bank is a competitor of Silver Bank in the US\" said John Doe.\n",
    "\n",
    "Output: (Named Entities)\n",
    "Golden Bank: company, Silver Bank: company, US: country, John Doe: person\n",
    "\n",
    "Input:\n",
    "Alphabet Inc's Google said on Friday it would prohibit websites and apps that use its advertising technology from running ads on \"dangerous content\" that goes against scientific consensus during the coronavirus pandemic.\n",
    "\n",
    "Output: (Named Entities)\n",
    "Alphabet Inc: company,  Google: company division, Friday: day of the week, coronavirus pandemic: event\n",
    "\n",
    "Input:\n",
    "{sample}\n",
    "\n",
    "Output: (Named Entities)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=\"TikTok: company, UK government: organization, London: location, China: country\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "input_str = \"TikTok: company, UK government: organization, London: location, China: country \"\n",
    "\n",
    "def parse_string_to_touple_list(input_str):\n",
    "    # Regular expression pattern to match 'key: value' pairs\n",
    "    # Adjust the pattern as needed to handle different formats\n",
    "    pattern = r'(\\w[\\w\\s]*?)\\s*:\\s*([\\w\\s]+)'\n",
    "\n",
    "    # Find all matches and convert them to tuples\n",
    "    tuples_list = re.findall(pattern, input_str)\n",
    "    \n",
    "    # remove any leading or trailing spaces as well as newlines from the keys and values\n",
    "    tuples_list = [(key.strip(), value.strip()) for key, value in tuples_list]   \n",
    "    \n",
    "    return tuples_list\n",
    "\n",
    "\n",
    "\n",
    "# Display the list of tuples\n",
    "print(parse_string_to_touple_list(input_str))\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df.copy()\n",
    "# Initialize the 'named_entities' column with default values\n",
    "df_copy['named_entities'] = [None] * len(df_copy)\n",
    "\n",
    "for i in range(df_copy.shape[0]):\n",
    "    named_entities=get_completion(df_copy['Description'][i], prompt_string_named_entities, granite_13_instruct_model)\n",
    "    # parse the named_entities string into a list of tuples and store it in a new column called 'named_entities'\n",
    "    df_copy['named_entities'][i] = parse_string_to_touple_list(named_entities)\n",
    "    \n",
    "df_copy.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "def process_row(index, row):\n",
    "    named_entities = get_completion(row['Description'], prompt_string_named_entities, granite_13_instruct_model)\n",
    "    return index, parse_string_to_touple_list(named_entities)\n",
    "\n",
    "# Assuming df_copy is your DataFrame\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    # Creating a list of futures\n",
    "    futures = [executor.submit(process_row, i, row) for i, row in df_copy.iterrows()]\n",
    "\n",
    "    # Retrieving results and updating the DataFrame\n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        index, named_entities = future.result()\n",
    "        df_copy.at[index, 'named_entities'] = named_entities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all company names from the named_entities column\n",
    "company_names = df_copy['named_entities'].apply(\n",
    "    lambda x: [tuple[0] for tuple in x if tuple[1] == 'company'] if x is not None else []\n",
    ")\n",
    "company_names.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the most common company names\n",
    "from collections import Counter\n",
    "company_names = Counter([item for sublist in company_names for item in sublist])\n",
    "company_names.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extract key actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_string_key_actions=\"\"\"\n",
    "You are the assistant of a fond manager. To help your boss you create super short summaries of financial news headlines called \"key actions\". Those key actions are no more than 3 words. Here are a few examples\n",
    "\n",
    "Input:\n",
    "TikTok considers London and other locations for headquarters,Jul 18 2020,\"TikTok has been in discussions with the UK government over the past few months to locate its headquarters in London, a source familiar with the matter said, as part of a strategy to distance itself from its Chinese ownership\n",
    "Output (2-3 words keyaction):\n",
    "Locate headquarters\n",
    "\n",
    "Input:\n",
    "Disney cuts ad spending on Facebook amid growing boycott: WSJ,Jul 18 2020,\"Walt Disney  has become the latest company to slash its advertising spending on Facebook Inc  as the social media giant faces an ad boycott over its handling of hate speech and controversial content, the Wall Street Journal reported on Saturday, citing people familiar with the situation.\"\n",
    "Output (2-3 words keyaction):\n",
    "Slash advertising\n",
    "\n",
    "Input:\n",
    "Twitter says attackers downloaded data from up to eight non-verified accounts,Jul 18 2020,Twitter Inc said on Saturday that hackers were able to download account information for up to eight accounts involved in the hack of its systems this week, but said none of them were verified accounts.\n",
    "Output (2-3 words keyaction):\n",
    "Hackers downloaded data\n",
    "\n",
    "Input:\n",
    "U.S. Republicans seek liability protections as coronavirus aid battle looms,Jul 17 2020,A battle in the U.S. Congress over a new coronavirus-aid bill began on Friday as Republicans were putting the finishing touches on provisions granting liability protections for a wide range of entities resuming operations amid the pandemic.\n",
    "Output (2-3 words keyaction):\n",
    "Seek liability protections\n",
    "\n",
    "Input:\n",
    "Senator asks Twitter about claim worker was paid to help with hack,Jul 17 2020,\"Senator Josh Hawley, a Republican who closely follows tech issues, pressed Twitter Chief Executive Jack Dorsey on Friday on whether a company employee had been paid to assist with a hack of high-profile accounts this week aimed at scamming readers.\"\n",
    "Output (2-3 words keyaction):\n",
    "Senator asks\n",
    "\n",
    "Now you do it:\n",
    "\n",
    "Input:\n",
    "{sample}\n",
    "\n",
    "Output (2-3 words keyaction):\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy_2 = df_copy.copy()\n",
    "# Initialize the 'named_entities' column with default values\n",
    "df_copy['key_action'] = [None] * len(df_copy)\n",
    "\n",
    "for i in range(10):\n",
    "    key_action=get_completion(df_copy['Description'][i], prompt_string_key_actions, llame_2_70b_model)\n",
    "    print(key_action)\n",
    "    df_copy['key_action'][i] = key_action\n",
    "    \n",
    "df_copy.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
